{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2eb837ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import InputLayer,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e96764e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.112522</td>\n",
       "      <td>-2.827204</td>\n",
       "      <td>-3.773897</td>\n",
       "      <td>-4.349751</td>\n",
       "      <td>-4.376041</td>\n",
       "      <td>-3.474986</td>\n",
       "      <td>-2.181408</td>\n",
       "      <td>-1.818286</td>\n",
       "      <td>-1.250522</td>\n",
       "      <td>-0.477492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792168</td>\n",
       "      <td>0.933541</td>\n",
       "      <td>0.796958</td>\n",
       "      <td>0.578621</td>\n",
       "      <td>0.257740</td>\n",
       "      <td>0.228077</td>\n",
       "      <td>0.123431</td>\n",
       "      <td>0.925286</td>\n",
       "      <td>0.193137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.100878</td>\n",
       "      <td>-3.996840</td>\n",
       "      <td>-4.285843</td>\n",
       "      <td>-4.506579</td>\n",
       "      <td>-4.022377</td>\n",
       "      <td>-3.234368</td>\n",
       "      <td>-1.566126</td>\n",
       "      <td>-0.992258</td>\n",
       "      <td>-0.754680</td>\n",
       "      <td>0.042321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538356</td>\n",
       "      <td>0.656881</td>\n",
       "      <td>0.787490</td>\n",
       "      <td>0.724046</td>\n",
       "      <td>0.555784</td>\n",
       "      <td>0.476333</td>\n",
       "      <td>0.773820</td>\n",
       "      <td>1.119621</td>\n",
       "      <td>-1.436250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.567088</td>\n",
       "      <td>-2.593450</td>\n",
       "      <td>-3.874230</td>\n",
       "      <td>-4.584095</td>\n",
       "      <td>-4.187449</td>\n",
       "      <td>-3.151462</td>\n",
       "      <td>-1.742940</td>\n",
       "      <td>-1.490659</td>\n",
       "      <td>-1.183580</td>\n",
       "      <td>-0.394229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886073</td>\n",
       "      <td>0.531452</td>\n",
       "      <td>0.311377</td>\n",
       "      <td>-0.021919</td>\n",
       "      <td>-0.713683</td>\n",
       "      <td>-0.532197</td>\n",
       "      <td>0.321097</td>\n",
       "      <td>0.904227</td>\n",
       "      <td>-0.421797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.490473</td>\n",
       "      <td>-1.914407</td>\n",
       "      <td>-3.616364</td>\n",
       "      <td>-4.318823</td>\n",
       "      <td>-4.268016</td>\n",
       "      <td>-3.881110</td>\n",
       "      <td>-2.993280</td>\n",
       "      <td>-1.671131</td>\n",
       "      <td>-1.333884</td>\n",
       "      <td>-0.965629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350816</td>\n",
       "      <td>0.499111</td>\n",
       "      <td>0.600345</td>\n",
       "      <td>0.842069</td>\n",
       "      <td>0.952074</td>\n",
       "      <td>0.990133</td>\n",
       "      <td>1.086798</td>\n",
       "      <td>1.403011</td>\n",
       "      <td>-0.383564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800232</td>\n",
       "      <td>-0.874252</td>\n",
       "      <td>-2.384761</td>\n",
       "      <td>-3.973292</td>\n",
       "      <td>-4.338224</td>\n",
       "      <td>-3.802422</td>\n",
       "      <td>-2.534510</td>\n",
       "      <td>-1.783423</td>\n",
       "      <td>-1.594450</td>\n",
       "      <td>-0.753199</td>\n",
       "      <td>...</td>\n",
       "      <td>1.148884</td>\n",
       "      <td>0.958434</td>\n",
       "      <td>1.059025</td>\n",
       "      <td>1.371682</td>\n",
       "      <td>1.277392</td>\n",
       "      <td>0.960304</td>\n",
       "      <td>0.971020</td>\n",
       "      <td>1.614392</td>\n",
       "      <td>1.421456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>0.608558</td>\n",
       "      <td>-0.335651</td>\n",
       "      <td>-0.990948</td>\n",
       "      <td>-1.784153</td>\n",
       "      <td>-2.626145</td>\n",
       "      <td>-2.957065</td>\n",
       "      <td>-2.931897</td>\n",
       "      <td>-2.664816</td>\n",
       "      <td>-2.090137</td>\n",
       "      <td>-1.461841</td>\n",
       "      <td>...</td>\n",
       "      <td>1.757705</td>\n",
       "      <td>2.291923</td>\n",
       "      <td>2.704595</td>\n",
       "      <td>2.451519</td>\n",
       "      <td>2.017396</td>\n",
       "      <td>1.704358</td>\n",
       "      <td>1.688542</td>\n",
       "      <td>1.629593</td>\n",
       "      <td>1.342651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>-2.060402</td>\n",
       "      <td>-2.860116</td>\n",
       "      <td>-3.405074</td>\n",
       "      <td>-3.748719</td>\n",
       "      <td>-3.513561</td>\n",
       "      <td>-3.006545</td>\n",
       "      <td>-2.234850</td>\n",
       "      <td>-1.593270</td>\n",
       "      <td>-1.075279</td>\n",
       "      <td>-0.976047</td>\n",
       "      <td>...</td>\n",
       "      <td>1.388947</td>\n",
       "      <td>2.079675</td>\n",
       "      <td>2.433375</td>\n",
       "      <td>2.159484</td>\n",
       "      <td>1.819747</td>\n",
       "      <td>1.534767</td>\n",
       "      <td>1.696818</td>\n",
       "      <td>1.483832</td>\n",
       "      <td>1.047612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-1.122969</td>\n",
       "      <td>-2.252925</td>\n",
       "      <td>-2.867628</td>\n",
       "      <td>-3.358605</td>\n",
       "      <td>-3.167849</td>\n",
       "      <td>-2.638360</td>\n",
       "      <td>-1.664162</td>\n",
       "      <td>-0.935655</td>\n",
       "      <td>-0.866953</td>\n",
       "      <td>-0.645363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.472419</td>\n",
       "      <td>-1.310147</td>\n",
       "      <td>-2.029521</td>\n",
       "      <td>-3.221294</td>\n",
       "      <td>-4.176790</td>\n",
       "      <td>-4.009720</td>\n",
       "      <td>-2.874136</td>\n",
       "      <td>-2.008369</td>\n",
       "      <td>-1.808334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-0.547705</td>\n",
       "      <td>-1.889545</td>\n",
       "      <td>-2.839779</td>\n",
       "      <td>-3.457912</td>\n",
       "      <td>-3.929149</td>\n",
       "      <td>-3.966026</td>\n",
       "      <td>-3.492560</td>\n",
       "      <td>-2.695270</td>\n",
       "      <td>-1.849691</td>\n",
       "      <td>-1.374321</td>\n",
       "      <td>...</td>\n",
       "      <td>1.258419</td>\n",
       "      <td>1.907530</td>\n",
       "      <td>2.280888</td>\n",
       "      <td>1.895242</td>\n",
       "      <td>1.437702</td>\n",
       "      <td>1.193433</td>\n",
       "      <td>1.261335</td>\n",
       "      <td>1.150449</td>\n",
       "      <td>0.804932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>-1.351779</td>\n",
       "      <td>-2.209006</td>\n",
       "      <td>-2.520225</td>\n",
       "      <td>-3.061475</td>\n",
       "      <td>-3.065141</td>\n",
       "      <td>-3.030739</td>\n",
       "      <td>-2.622720</td>\n",
       "      <td>-2.044092</td>\n",
       "      <td>-1.295874</td>\n",
       "      <td>-0.733839</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.512234</td>\n",
       "      <td>-2.076075</td>\n",
       "      <td>-2.586042</td>\n",
       "      <td>-3.322799</td>\n",
       "      <td>-3.627311</td>\n",
       "      <td>-3.437038</td>\n",
       "      <td>-2.260023</td>\n",
       "      <td>-1.577823</td>\n",
       "      <td>-0.684531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4998 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.112522 -2.827204 -3.773897 -4.349751 -4.376041 -3.474986 -2.181408   \n",
       "1    -1.100878 -3.996840 -4.285843 -4.506579 -4.022377 -3.234368 -1.566126   \n",
       "2    -0.567088 -2.593450 -3.874230 -4.584095 -4.187449 -3.151462 -1.742940   \n",
       "3     0.490473 -1.914407 -3.616364 -4.318823 -4.268016 -3.881110 -2.993280   \n",
       "4     0.800232 -0.874252 -2.384761 -3.973292 -4.338224 -3.802422 -2.534510   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4993  0.608558 -0.335651 -0.990948 -1.784153 -2.626145 -2.957065 -2.931897   \n",
       "4994 -2.060402 -2.860116 -3.405074 -3.748719 -3.513561 -3.006545 -2.234850   \n",
       "4995 -1.122969 -2.252925 -2.867628 -3.358605 -3.167849 -2.638360 -1.664162   \n",
       "4996 -0.547705 -1.889545 -2.839779 -3.457912 -3.929149 -3.966026 -3.492560   \n",
       "4997 -1.351779 -2.209006 -2.520225 -3.061475 -3.065141 -3.030739 -2.622720   \n",
       "\n",
       "           7         8         9    ...       131       132       133  \\\n",
       "0    -1.818286 -1.250522 -0.477492  ...  0.792168  0.933541  0.796958   \n",
       "1    -0.992258 -0.754680  0.042321  ...  0.538356  0.656881  0.787490   \n",
       "2    -1.490659 -1.183580 -0.394229  ...  0.886073  0.531452  0.311377   \n",
       "3    -1.671131 -1.333884 -0.965629  ...  0.350816  0.499111  0.600345   \n",
       "4    -1.783423 -1.594450 -0.753199  ...  1.148884  0.958434  1.059025   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4993 -2.664816 -2.090137 -1.461841  ...  1.757705  2.291923  2.704595   \n",
       "4994 -1.593270 -1.075279 -0.976047  ...  1.388947  2.079675  2.433375   \n",
       "4995 -0.935655 -0.866953 -0.645363  ... -0.472419 -1.310147 -2.029521   \n",
       "4996 -2.695270 -1.849691 -1.374321  ...  1.258419  1.907530  2.280888   \n",
       "4997 -2.044092 -1.295874 -0.733839  ... -1.512234 -2.076075 -2.586042   \n",
       "\n",
       "           134       135       136       137       138       139  140  \n",
       "0     0.578621  0.257740  0.228077  0.123431  0.925286  0.193137    1  \n",
       "1     0.724046  0.555784  0.476333  0.773820  1.119621 -1.436250    1  \n",
       "2    -0.021919 -0.713683 -0.532197  0.321097  0.904227 -0.421797    1  \n",
       "3     0.842069  0.952074  0.990133  1.086798  1.403011 -0.383564    1  \n",
       "4     1.371682  1.277392  0.960304  0.971020  1.614392  1.421456    1  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "4993  2.451519  2.017396  1.704358  1.688542  1.629593  1.342651    0  \n",
       "4994  2.159484  1.819747  1.534767  1.696818  1.483832  1.047612    0  \n",
       "4995 -3.221294 -4.176790 -4.009720 -2.874136 -2.008369 -1.808334    0  \n",
       "4996  1.895242  1.437702  1.193433  1.261335  1.150449  0.804932    0  \n",
       "4997 -3.322799 -3.627311 -3.437038 -2.260023 -1.577823 -0.684531    0  \n",
       "\n",
       "[4998 rows x 141 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('ecg_autoencoder_dataset.csv',header=None)\n",
    "x=data.values\n",
    "y=np.zeros(x.shape[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b403f87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3998, 141)\n",
      "(1000, 141)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "613cd428",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ff089d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=x_train.shape[1]\n",
    "embedding_dim=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "962f99d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=Sequential([\n",
    "    InputLayer(input_shape=(input_dim,)),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(embedding_dim,activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b8f0a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder=Sequential([\n",
    "    InputLayer(input_shape=(embedding_dim,)),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(input_dim,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f11ee5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 3s 8ms/step - loss: 0.0566 - val_loss: 2.4358e-04\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 1.4362e-04 - val_loss: 6.5776e-05\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 4.8265e-05 - val_loss: 2.9429e-05\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3161e-05 - val_loss: 1.6959e-05\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.3445e-05 - val_loss: 1.0552e-05\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 8.5826e-06 - val_loss: 7.4290e-06\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 5.9495e-06 - val_loss: 5.4076e-06\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 4.3078e-06 - val_loss: 4.1249e-06\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 3.2377e-06 - val_loss: 3.2540e-06\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 2.5035e-06 - val_loss: 2.6227e-06\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_7 (Sequential)   (None, 16)                5072      \n",
      "                                                                 \n",
      " sequential_8 (Sequential)   (None, 141)               5197      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10269 (40.11 KB)\n",
      "Trainable params: 10269 (40.11 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Sequential([encoder, decoder])\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.fit(x_train, y_train, epochs=10, batch_size=32, shuffle=True, validation_data=(x_test, y_test))\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd2eea30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions=autoencoder.predict(x_test)\n",
    "mse=np.mean((x_test-predictions)**2,axis=1)\n",
    "\n",
    "threshold=np.percentile(mse,95)\n",
    "y_test_pred=np.where(mse>threshold,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfc79f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_test,y_test_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea34be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
