{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb837ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 15:49:32.896488: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-16 15:49:32.942886: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-16 15:49:32.942931: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-16 15:49:32.942977: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-16 15:49:32.951585: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-16 15:49:32.952547: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-16 15:49:33.908326: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import InputLayer,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e96764e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-0.11252183</th>\n",
       "      <th>-2.8272038</th>\n",
       "      <th>-3.7738969</th>\n",
       "      <th>-4.3497511</th>\n",
       "      <th>-4.376041</th>\n",
       "      <th>-3.4749863</th>\n",
       "      <th>-2.1814082</th>\n",
       "      <th>-1.8182865</th>\n",
       "      <th>-1.2505219</th>\n",
       "      <th>-0.47749208</th>\n",
       "      <th>...</th>\n",
       "      <th>0.79216787</th>\n",
       "      <th>0.93354122</th>\n",
       "      <th>0.79695779</th>\n",
       "      <th>0.57862066</th>\n",
       "      <th>0.2577399</th>\n",
       "      <th>0.22807718</th>\n",
       "      <th>0.12343082</th>\n",
       "      <th>0.92528624</th>\n",
       "      <th>0.19313742</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.100878</td>\n",
       "      <td>-3.996840</td>\n",
       "      <td>-4.285843</td>\n",
       "      <td>-4.506579</td>\n",
       "      <td>-4.022377</td>\n",
       "      <td>-3.234368</td>\n",
       "      <td>-1.566126</td>\n",
       "      <td>-0.992258</td>\n",
       "      <td>-0.754680</td>\n",
       "      <td>0.042321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538356</td>\n",
       "      <td>0.656881</td>\n",
       "      <td>0.787490</td>\n",
       "      <td>0.724046</td>\n",
       "      <td>0.555784</td>\n",
       "      <td>0.476333</td>\n",
       "      <td>0.773820</td>\n",
       "      <td>1.119621</td>\n",
       "      <td>-1.436250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.567088</td>\n",
       "      <td>-2.593450</td>\n",
       "      <td>-3.874230</td>\n",
       "      <td>-4.584095</td>\n",
       "      <td>-4.187449</td>\n",
       "      <td>-3.151462</td>\n",
       "      <td>-1.742940</td>\n",
       "      <td>-1.490659</td>\n",
       "      <td>-1.183580</td>\n",
       "      <td>-0.394229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886073</td>\n",
       "      <td>0.531452</td>\n",
       "      <td>0.311377</td>\n",
       "      <td>-0.021919</td>\n",
       "      <td>-0.713683</td>\n",
       "      <td>-0.532197</td>\n",
       "      <td>0.321097</td>\n",
       "      <td>0.904227</td>\n",
       "      <td>-0.421797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.490473</td>\n",
       "      <td>-1.914407</td>\n",
       "      <td>-3.616364</td>\n",
       "      <td>-4.318823</td>\n",
       "      <td>-4.268016</td>\n",
       "      <td>-3.881110</td>\n",
       "      <td>-2.993280</td>\n",
       "      <td>-1.671131</td>\n",
       "      <td>-1.333884</td>\n",
       "      <td>-0.965629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350816</td>\n",
       "      <td>0.499111</td>\n",
       "      <td>0.600345</td>\n",
       "      <td>0.842069</td>\n",
       "      <td>0.952074</td>\n",
       "      <td>0.990133</td>\n",
       "      <td>1.086798</td>\n",
       "      <td>1.403011</td>\n",
       "      <td>-0.383564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.800232</td>\n",
       "      <td>-0.874252</td>\n",
       "      <td>-2.384761</td>\n",
       "      <td>-3.973292</td>\n",
       "      <td>-4.338224</td>\n",
       "      <td>-3.802422</td>\n",
       "      <td>-2.534510</td>\n",
       "      <td>-1.783423</td>\n",
       "      <td>-1.594450</td>\n",
       "      <td>-0.753199</td>\n",
       "      <td>...</td>\n",
       "      <td>1.148884</td>\n",
       "      <td>0.958434</td>\n",
       "      <td>1.059025</td>\n",
       "      <td>1.371682</td>\n",
       "      <td>1.277392</td>\n",
       "      <td>0.960304</td>\n",
       "      <td>0.971020</td>\n",
       "      <td>1.614392</td>\n",
       "      <td>1.421456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.507674</td>\n",
       "      <td>-3.574550</td>\n",
       "      <td>-4.478011</td>\n",
       "      <td>-4.408275</td>\n",
       "      <td>-3.321242</td>\n",
       "      <td>-2.105171</td>\n",
       "      <td>-1.481048</td>\n",
       "      <td>-1.301362</td>\n",
       "      <td>-0.498240</td>\n",
       "      <td>-0.286928</td>\n",
       "      <td>...</td>\n",
       "      <td>1.089068</td>\n",
       "      <td>0.983369</td>\n",
       "      <td>1.014124</td>\n",
       "      <td>0.952629</td>\n",
       "      <td>0.749326</td>\n",
       "      <td>1.007076</td>\n",
       "      <td>1.634990</td>\n",
       "      <td>1.493365</td>\n",
       "      <td>-0.783134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>0.608558</td>\n",
       "      <td>-0.335651</td>\n",
       "      <td>-0.990948</td>\n",
       "      <td>-1.784153</td>\n",
       "      <td>-2.626145</td>\n",
       "      <td>-2.957065</td>\n",
       "      <td>-2.931897</td>\n",
       "      <td>-2.664816</td>\n",
       "      <td>-2.090137</td>\n",
       "      <td>-1.461841</td>\n",
       "      <td>...</td>\n",
       "      <td>1.757705</td>\n",
       "      <td>2.291923</td>\n",
       "      <td>2.704595</td>\n",
       "      <td>2.451519</td>\n",
       "      <td>2.017396</td>\n",
       "      <td>1.704358</td>\n",
       "      <td>1.688542</td>\n",
       "      <td>1.629593</td>\n",
       "      <td>1.342651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>-2.060402</td>\n",
       "      <td>-2.860116</td>\n",
       "      <td>-3.405074</td>\n",
       "      <td>-3.748719</td>\n",
       "      <td>-3.513561</td>\n",
       "      <td>-3.006545</td>\n",
       "      <td>-2.234850</td>\n",
       "      <td>-1.593270</td>\n",
       "      <td>-1.075279</td>\n",
       "      <td>-0.976047</td>\n",
       "      <td>...</td>\n",
       "      <td>1.388947</td>\n",
       "      <td>2.079675</td>\n",
       "      <td>2.433375</td>\n",
       "      <td>2.159484</td>\n",
       "      <td>1.819747</td>\n",
       "      <td>1.534767</td>\n",
       "      <td>1.696818</td>\n",
       "      <td>1.483832</td>\n",
       "      <td>1.047612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>-1.122969</td>\n",
       "      <td>-2.252925</td>\n",
       "      <td>-2.867628</td>\n",
       "      <td>-3.358605</td>\n",
       "      <td>-3.167849</td>\n",
       "      <td>-2.638360</td>\n",
       "      <td>-1.664162</td>\n",
       "      <td>-0.935655</td>\n",
       "      <td>-0.866953</td>\n",
       "      <td>-0.645363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.472419</td>\n",
       "      <td>-1.310147</td>\n",
       "      <td>-2.029521</td>\n",
       "      <td>-3.221294</td>\n",
       "      <td>-4.176790</td>\n",
       "      <td>-4.009720</td>\n",
       "      <td>-2.874136</td>\n",
       "      <td>-2.008369</td>\n",
       "      <td>-1.808334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-0.547705</td>\n",
       "      <td>-1.889545</td>\n",
       "      <td>-2.839779</td>\n",
       "      <td>-3.457912</td>\n",
       "      <td>-3.929149</td>\n",
       "      <td>-3.966026</td>\n",
       "      <td>-3.492560</td>\n",
       "      <td>-2.695270</td>\n",
       "      <td>-1.849691</td>\n",
       "      <td>-1.374321</td>\n",
       "      <td>...</td>\n",
       "      <td>1.258419</td>\n",
       "      <td>1.907530</td>\n",
       "      <td>2.280888</td>\n",
       "      <td>1.895242</td>\n",
       "      <td>1.437702</td>\n",
       "      <td>1.193433</td>\n",
       "      <td>1.261335</td>\n",
       "      <td>1.150449</td>\n",
       "      <td>0.804932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-1.351779</td>\n",
       "      <td>-2.209006</td>\n",
       "      <td>-2.520225</td>\n",
       "      <td>-3.061475</td>\n",
       "      <td>-3.065141</td>\n",
       "      <td>-3.030739</td>\n",
       "      <td>-2.622720</td>\n",
       "      <td>-2.044092</td>\n",
       "      <td>-1.295874</td>\n",
       "      <td>-0.733839</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.512234</td>\n",
       "      <td>-2.076075</td>\n",
       "      <td>-2.586042</td>\n",
       "      <td>-3.322799</td>\n",
       "      <td>-3.627311</td>\n",
       "      <td>-3.437038</td>\n",
       "      <td>-2.260023</td>\n",
       "      <td>-1.577823</td>\n",
       "      <td>-0.684531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4997 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      -0.11252183  -2.8272038  -3.7738969  -4.3497511  -4.376041  -3.4749863   \n",
       "0       -1.100878   -3.996840   -4.285843   -4.506579  -4.022377   -3.234368  \\\n",
       "1       -0.567088   -2.593450   -3.874230   -4.584095  -4.187449   -3.151462   \n",
       "2        0.490473   -1.914407   -3.616364   -4.318823  -4.268016   -3.881110   \n",
       "3        0.800232   -0.874252   -2.384761   -3.973292  -4.338224   -3.802422   \n",
       "4       -1.507674   -3.574550   -4.478011   -4.408275  -3.321242   -2.105171   \n",
       "...           ...         ...         ...         ...        ...         ...   \n",
       "4992     0.608558   -0.335651   -0.990948   -1.784153  -2.626145   -2.957065   \n",
       "4993    -2.060402   -2.860116   -3.405074   -3.748719  -3.513561   -3.006545   \n",
       "4994    -1.122969   -2.252925   -2.867628   -3.358605  -3.167849   -2.638360   \n",
       "4995    -0.547705   -1.889545   -2.839779   -3.457912  -3.929149   -3.966026   \n",
       "4996    -1.351779   -2.209006   -2.520225   -3.061475  -3.065141   -3.030739   \n",
       "\n",
       "      -2.1814082  -1.8182865  -1.2505219  -0.47749208  ...  0.79216787   \n",
       "0      -1.566126   -0.992258   -0.754680     0.042321  ...    0.538356  \\\n",
       "1      -1.742940   -1.490659   -1.183580    -0.394229  ...    0.886073   \n",
       "2      -2.993280   -1.671131   -1.333884    -0.965629  ...    0.350816   \n",
       "3      -2.534510   -1.783423   -1.594450    -0.753199  ...    1.148884   \n",
       "4      -1.481048   -1.301362   -0.498240    -0.286928  ...    1.089068   \n",
       "...          ...         ...         ...          ...  ...         ...   \n",
       "4992   -2.931897   -2.664816   -2.090137    -1.461841  ...    1.757705   \n",
       "4993   -2.234850   -1.593270   -1.075279    -0.976047  ...    1.388947   \n",
       "4994   -1.664162   -0.935655   -0.866953    -0.645363  ...   -0.472419   \n",
       "4995   -3.492560   -2.695270   -1.849691    -1.374321  ...    1.258419   \n",
       "4996   -2.622720   -2.044092   -1.295874    -0.733839  ...   -1.512234   \n",
       "\n",
       "      0.93354122  0.79695779  0.57862066  0.2577399  0.22807718  0.12343082   \n",
       "0       0.656881    0.787490    0.724046   0.555784    0.476333    0.773820  \\\n",
       "1       0.531452    0.311377   -0.021919  -0.713683   -0.532197    0.321097   \n",
       "2       0.499111    0.600345    0.842069   0.952074    0.990133    1.086798   \n",
       "3       0.958434    1.059025    1.371682   1.277392    0.960304    0.971020   \n",
       "4       0.983369    1.014124    0.952629   0.749326    1.007076    1.634990   \n",
       "...          ...         ...         ...        ...         ...         ...   \n",
       "4992    2.291923    2.704595    2.451519   2.017396    1.704358    1.688542   \n",
       "4993    2.079675    2.433375    2.159484   1.819747    1.534767    1.696818   \n",
       "4994   -1.310147   -2.029521   -3.221294  -4.176790   -4.009720   -2.874136   \n",
       "4995    1.907530    2.280888    1.895242   1.437702    1.193433    1.261335   \n",
       "4996   -2.076075   -2.586042   -3.322799  -3.627311   -3.437038   -2.260023   \n",
       "\n",
       "      0.92528624  0.19313742  1  \n",
       "0       1.119621   -1.436250  1  \n",
       "1       0.904227   -0.421797  1  \n",
       "2       1.403011   -0.383564  1  \n",
       "3       1.614392    1.421456  1  \n",
       "4       1.493365   -0.783134  1  \n",
       "...          ...         ... ..  \n",
       "4992    1.629593    1.342651  0  \n",
       "4993    1.483832    1.047612  0  \n",
       "4994   -2.008369   -1.808334  0  \n",
       "4995    1.150449    0.804932  0  \n",
       "4996   -1.577823   -0.684531  0  \n",
       "\n",
       "[4997 rows x 141 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./datasets/ECGdataset(Ass4)/ecg_autoencoder_dataset.csv\")\n",
    "x=data.values\n",
    "y=np.zeros(x.shape[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b403f87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3997, 141)\n",
      "(1000, 141)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613cd428",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ff089d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=x_train.shape[1]\n",
    "embedding_dim=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "962f99d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 15:49:43.212422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-16 15:49:43.212879: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "encoder=Sequential([\n",
    "    InputLayer(input_shape=(input_dim,)),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(embedding_dim,activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b8f0a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder=Sequential([\n",
    "    InputLayer(input_shape=(embedding_dim,)),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(input_dim,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f11ee5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.0658 - val_loss: 2.2136e-04\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1229e-04 - val_loss: 6.1305e-05\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.6043e-05 - val_loss: 2.5096e-05\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5088e-05 - val_loss: 1.2029e-05\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.4721e-06 - val_loss: 6.6546e-06\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.1720e-06 - val_loss: 4.1237e-06\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.6285e-06 - val_loss: 2.8636e-06\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.7950e-06 - val_loss: 2.0817e-06\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2981e-06 - val_loss: 1.5837e-06\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.7801e-07 - val_loss: 1.2449e-06\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 16)                5072      \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 141)               5197      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10269 (40.11 KB)\n",
      "Trainable params: 10269 (40.11 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Sequential([encoder, decoder])\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.fit(x_train, y_train, epochs=10, batch_size=32, shuffle=True, validation_data=(x_test, y_test))\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd2eea30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions=autoencoder.predict(x_test)\n",
    "mse=np.mean((x_test-predictions)**2,axis=1)\n",
    "\n",
    "threshold=np.percentile(mse,95)\n",
    "y_test_pred=np.where(mse>threshold,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfc79f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_test,y_test_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea34be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
